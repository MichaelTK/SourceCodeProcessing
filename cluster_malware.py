#!/usr/bin/python3

print(__doc__)

VECTOR_FILE_PATH = "/home/k1462425/Documents/Research/MalwareSourceTestSet/SCAAarffs/compiled_12authors120files.arff"
VECTOR_FILE_PATH2 = "/home/k1462425/Documents/Research/MalwareSourceTestSet/SCAAarffs/syntactical_features_vector"
lines = []

#import plotly.plotly as py
#import plotly.graph_objs as go

import matplotlib.pyplot as plt
import numpy as np
import math

import sklearn
from sklearn.cluster import DBSCAN
from sklearn import metrics
from sklearn.datasets.samples_generator import make_blobs
from sklearn.preprocessing import StandardScaler

def load_vectors():
    global lines
    with open(VECTOR_FILE_PATH2) as fp:
        line = fp.readline()
        cnt = 1
        #while line:
        while line:
            splitline = line.strip().split(',')
            splitline.pop(0)
            splitline.pop(-1)
            splitline.pop(-27) #comment this out if dealing only with syntactical features
            try:
                for idx,value in enumerate(splitline):
                    if value == '-Infinity':
                        #print("INFINITY")
                        splitline[idx] = '0'
                    elif value == 'TRUE':
                        #print("TRUE")
                        splitline[idx] = '1'
                    elif value == 'FALSE':
                        #print("FALSE")
                        splitline[idx] = '0'
                    elif len(value) > 2:
                        if  (value[1] == '.' or value[2] == '.') and len(value) > 4:
                            #print(value)
                            splitline[idx] = truncate(value, 3)
                    if value == 'NaN':
                        #print('NaN')
                        splitline[idx] = '0'
#                    elif value[0] == '-':
#                        splitline[idx] = 0
            except:
                print("An exception occurred. Probably string index out of bounds")
            lines.append(splitline)
            line = fp.readline()
            cnt += 1

def truncate(f, n):
    '''Truncates/pads a float f to n decimal places without rounding'''
    s = '{}'.format(f)
    if 'e' in s or 'E' in s:
        return '{0:.{1}f}'.format(f, n)
    i, p, d = s.partition('.')
    return '.'.join([i, (d+'0'*n)[:n]])

def integerise():
    global lines
    for line in lines:
        for idx, value in enumerate(line):
            #print(idx, value)
            #print(type(value))
            value = float(value)
            #value = value * 1000000
            #value = math.floor(value)
            #value = value/1000000
            #value = int(value)
            line[idx] = value

    print("There are "+str(len(lines))+" samples")


def cluster():
    #print(lines)
    centers = lines
    X, labels_true = make_blobs(n_samples=191, centers=centers, cluster_std=0.4,
                                random_state=0)

    X = StandardScaler().fit_transform(X)
    db = DBSCAN(eps=250, min_samples=2).fit(X)
    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
    core_samples_mask[db.core_sample_indices_] = True
    labels = db.labels_

    print (lines)
    # Number of clusters in labels, ignoring noise if present.
    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)

    print('Estimated number of clusters: %d' % n_clusters_)
    print("Homogeneity: %0.3f" % metrics.homogeneity_score(labels_true, labels))
    print("Completeness: %0.3f" % metrics.completeness_score(labels_true, labels))
    print("V-measure: %0.3f" % metrics.v_measure_score(labels_true, labels))
    print("Adjusted Rand Index: %0.3f"
          % metrics.adjusted_rand_score(labels_true, labels))
    print("Adjusted Mutual Information: %0.3f"
          % metrics.adjusted_mutual_info_score(labels_true, labels))
    print("Silhouette Coefficient: %0.3f"
          % metrics.silhouette_score(X, labels))


    unique_labels = set(labels)
    colors = [plt.cm.Spectral(each)
          for each in np.linspace(0, 1, len(unique_labels))]
    for k, col in zip(unique_labels, colors):
        if k == -1:
            # Black used for noise.
            col = [0, 0, 0, 1]

        class_member_mask = (labels == k)

        xy = X[class_member_mask & core_samples_mask]
        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),
            markeredgecolor='k', markersize=14)

        xy = X[class_member_mask & ~core_samples_mask]
        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),
            markeredgecolor='k', markersize=6)

    plt.title('Estimated number of clusters: %d' % n_clusters_)
    plt.show()


if __name__ == '__main__':
    load_vectors()
    integerise()
    cluster()
